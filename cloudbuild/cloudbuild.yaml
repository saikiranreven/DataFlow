steps:
  # 1. Terraform infrastructure deployment
  - id: 'terraform-apply'
    name: 'hashicorp/terraform:1.5.7'
    args: ['init']
    dir: 'terraform'

  - id: 'terraform-apply'
    name: 'hashicorp/terraform:1.5.7'
    args: ['apply', '-auto-approve']
    dir: 'terraform'

  # 2. Deploy Dataflow pipeline (now step 2)
  - id: 'deploy-dataflow'
    name: 'python:3.10'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        pip install apache-beam[gcp]==2.54.0 && \
        python dataflow/pipeline.py \
          --project=bct-project-465419 \
          --region=us-central1 \
          --input_topic=projects/bct-project-465419/topics/stream-topic \
          --temp_location=gs://bct-project-465419-raw-backup/temp \
          --staging_location=gs://bct-project-465419-raw-backup/staging \
          --output_table=bct-project-465419:streaming_dataset.user_events \
          --output_path=gs://bct-project-465419-raw-backup/raw/events \
          --runner=DataflowRunner \
          --streaming
    waitFor: ['terraform-apply']

  # 3. Build and deploy Cloud Run service (now step 3)
  - id: 'build-publisher'
    name: 'gcr.io/cloud-builders/docker'
    args: ['build', '-t', 'gcr.io/bct-project-465419/pubsub-publisher', './publisher']
    waitFor: ['terraform-apply']

  - id: 'deploy-publisher'
    name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    args: 
      - 'gcloud'
      - 'run'
      - 'deploy'
      - 'pubsub-publisher'
      - '--image=gcr.io/bct-project-465419/pubsub-publisher'
      - '--platform=managed'
      - '--region=us-central1'
      - '--no-allow-unauthenticated'
      - '--memory=256Mi'
      - '--cpu=1'
    waitFor: ['build-publisher']

options:
  logging: CLOUD_LOGGING_ONLY
timeout: 1800s